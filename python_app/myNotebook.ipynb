{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer ID     Customer Name\n",
      "0          1.0          Jane Doe\n",
      "1          2.0        John Smith\n",
      "2          3.0        Dan Reeves\n",
      "3          NaN               NaN\n",
      "4          5.0    William Holden\n",
      "5          6.0     Jaztyn Forest\n",
      "6          7.0     Jackie Irving\n",
      "7          8.0  Matthew Stirling\n",
      "8          9.0         Emory Ted\n",
      "   Customer ID     Customer Name\n",
      "0          1.0          Jane Doe\n",
      "1          2.0        John Smith\n",
      "2          3.0        Dan Reeves\n",
      "4          5.0    William Holden\n",
      "5          6.0     Jaztyn Forest\n",
      "6          7.0     Jackie Irving\n",
      "7          8.0  Matthew Stirling\n",
      "8          9.0         Emory Ted\n",
      "Empty DataFrame\n",
      "Columns: [Customer ID, Customer Name]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#Loading csv customer data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "customerRaw = pd.read_csv(\"C:/Users/Admin/MVP_Library_Apprenticeship/python_app/raw_data/03_Library SystemCustomers.csv\")\n",
    "print(customerRaw)\n",
    "\n",
    "#Cleaning data\n",
    "\n",
    "df_cleaned = customerRaw.dropna(how='all')\n",
    "print(df_cleaned)\n",
    "\n",
    "#Dropping duplicates\n",
    "df_duplicates = df_cleaned[df_cleaned.duplicated()]\n",
    "print(df_duplicates)\n",
    "df_no_duplicates = df_duplicates.drop_duplicates()\n",
    "\n",
    "#save cleansed data\n",
    "df_cleaned.to_csv(\"output/notebook/customerCleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Id                                     Books Book checkout  \\\n",
      "0    1.0                       Catcher in the Rye   \"20/02/2023\"   \n",
      "1    2.0          Lord of the rings the two towers  \"24/03/2023\"   \n",
      "2    3.0  Lord of the rings the return of the kind  \"29/03/2023\"   \n",
      "3    4.0                                The hobbit  \"02/04/2023\"   \n",
      "4    5.0                                     Dune   \"02/04/2023\"   \n",
      "..   ...                                       ...           ...   \n",
      "109  NaN                                       NaN           NaN   \n",
      "110  NaN                                       NaN           NaN   \n",
      "111  NaN                                       NaN           NaN   \n",
      "112  NaN                                       NaN           NaN   \n",
      "113  NaN                                       NaN           NaN   \n",
      "\n",
      "    Book Returned Days allowed to borrow  Customer ID  \n",
      "0      25/02/2023                2 weeks          1.0  \n",
      "1      21/03/2023                2 weeks          2.0  \n",
      "2      25/03/2023                2 weeks          3.0  \n",
      "3      25/03/2023                2 weeks          4.0  \n",
      "4      25/03/2023                2 weeks          5.0  \n",
      "..            ...                    ...          ...  \n",
      "109           NaN                    NaN          NaN  \n",
      "110           NaN                    NaN          NaN  \n",
      "111           NaN                    NaN          NaN  \n",
      "112           NaN                    NaN          NaN  \n",
      "113           NaN                    NaN          NaN  \n",
      "\n",
      "[114 rows x 6 columns]\n",
      "      Id                                     Books Book checkout  \\\n",
      "0    1.0                       Catcher in the Rye   \"20/02/2023\"   \n",
      "1    2.0          Lord of the rings the two towers  \"24/03/2023\"   \n",
      "2    3.0  Lord of the rings the return of the kind  \"29/03/2023\"   \n",
      "3    4.0                                The hobbit  \"02/04/2023\"   \n",
      "4    5.0                                     Dune   \"02/04/2023\"   \n",
      "5    6.0                              Little Women  \"02/04/2023\"   \n",
      "6    7.0                                        IT  \"10/04/2063\"   \n",
      "7    8.0                                   Misery   \"15/04/2023\"   \n",
      "8    9.0                                  Catch 22  \"15/04/2023\"   \n",
      "9   10.0                              Animal Farm   \"20/04/2023\"   \n",
      "10  11.0                                      1984  \"23/04/2023\"   \n",
      "11  12.0                              Little Women  \"02/04/2023\"   \n",
      "12  13.0                              East of Eden  \"30/04/2023\"   \n",
      "13  14.0                   America Is in the Heart  \"01/05/2023\"   \n",
      "14  15.0                         Wuthering Heights  \"01/05/2023\"   \n",
      "15  16.0                                Dark Tales  \"15/05/2023\"   \n",
      "16  17.0                        The Bloody Chamber  \"32/05/2023\"   \n",
      "17  18.0                            Les Miserables  \"03/06/2023\"   \n",
      "18  19.0                                   Dracula  \"10/06/2023\"   \n",
      "19  20.0                              Frankenstein  \"01/06/2023\"   \n",
      "\n",
      "   Book Returned Days allowed to borrow  Customer ID  \n",
      "0     25/02/2023                2 weeks          1.0  \n",
      "1     21/03/2023                2 weeks          2.0  \n",
      "2     25/03/2023                2 weeks          3.0  \n",
      "3     25/03/2023                2 weeks          4.0  \n",
      "4     25/03/2023                2 weeks          5.0  \n",
      "5     01/05/2023                2 weeks          1.0  \n",
      "6     03/04/2023                2 weeks          6.0  \n",
      "7     03/04/2023                2 weeks          7.0  \n",
      "8     16/04/2023                2 weeks          7.0  \n",
      "9     24/04/2023                2 weeks          2.0  \n",
      "10    27/04/2023                2 weeks          8.0  \n",
      "11    01/05/2023                2 weeks          1.0  \n",
      "12    05/05/2023                2 weeks          2.0  \n",
      "13    07/05/2023                2 weeks          3.0  \n",
      "14    10/05/2023                2 weeks          9.0  \n",
      "15    01/06/2023                2 weeks          2.0  \n",
      "16    04/06/2023                2 weeks          3.0  \n",
      "17    07/06/2023                2 weeks          5.0  \n",
      "18    10/07/2023                2 weeks         10.0  \n",
      "19    20/06/2023                2 weeks          2.0  \n",
      "Empty DataFrame\n",
      "Columns: [Id, Books, Book checkout, Book Returned, Days allowed to borrow, Customer ID]\n",
      "Index: []\n",
      "Id                        float64\n",
      "Books                      object\n",
      "Book checkout              object\n",
      "Book Returned              object\n",
      "Days allowed to borrow     object\n",
      "Customer ID               float64\n",
      "dtype: object\n",
      "Id                               float64\n",
      "Books                             object\n",
      "Book checkout             datetime64[ns]\n",
      "Book Returned             datetime64[ns]\n",
      "Days allowed to borrow            object\n",
      "Customer ID                      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bookRaw = pd.read_csv(\"C:/Users/Admin/MVP_Library_Apprenticeship/python_app/raw_data/03_Library Systembook.csv\")\n",
    "print(bookRaw)\n",
    "\n",
    "#Cleaning data\n",
    "df_cleaned_book = bookRaw.dropna(how='all')\n",
    "\n",
    "df_cleaned_book_all = df_cleaned_book[~(df_cleaned_book[\"Books\"].isna() & df_cleaned_book[\"Customer ID\"].isna())]\n",
    "print(df_cleaned_book_all)\n",
    "\n",
    "#Dropping duplicates\n",
    "df_duplicates_book = df_cleaned_book_all[df_cleaned_book_all.duplicated()]\n",
    "print(df_duplicates_book)\n",
    "df_no_duplicates_book = df_cleaned_book_all.drop_duplicates()\n",
    "\n",
    "#Cheking types\n",
    "print(df_no_duplicates_book.dtypes)\n",
    "\n",
    "#Correcting Date types\n",
    "# Fix invalid dates manually (replace or remove)\n",
    "df_no_duplicates_book['Book checkout'] = df_no_duplicates_book['Book checkout'].str.replace('\"', '', regex=False)\n",
    "df_no_duplicates_book['Book checkout'] = df_no_duplicates_book['Book checkout'].apply(\n",
    "    lambda x: x if len(x.split('/')) == 3 and int(x.split('/')[0]) <= 31 else '01/01/2023'\n",
    ")\n",
    "df_no_duplicates_book['Book checkout'] = pd.to_datetime(df_no_duplicates_book['Book checkout'], dayfirst=True)\n",
    "\n",
    "# Fix invalid dates manually (replace or remove)\n",
    "df_no_duplicates_book['Book Returned'] = df_no_duplicates_book['Book Returned'].apply(\n",
    "    lambda x: x if len(x.split('/')) == 3 and int(x.split('/')[0]) <= 31 else '1970-01-01'\n",
    ")\n",
    "df_no_duplicates_book['Book Returned'] = pd.to_datetime(df_no_duplicates_book['Book Returned'], dayfirst=True)\n",
    "\n",
    "print(df_no_duplicates_book.dtypes)\n",
    "\n",
    "\n",
    "#save cleansed data\n",
    "df_no_duplicates_book.to_csv(\"output/notebook/bookCleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to SQL Server successfully.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine # type: ignore\n",
    "\n",
    "server = 'localhost'\n",
    "database = 'MVP_Library'\n",
    "driver = 'ODBC Driver 17 for SQL Server'\n",
    "\n",
    "connection_string = f'mssql+pyodbc://@{server}/{database}?trusted_connection=yes&driver={driver}'\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "import pandas as pd # type: ignore\n",
    "\n",
    "# Load cleaned CSVs\n",
    "df_customer = pd.read_csv('C:/Users/Admin/MVP_Library_Apprenticeship/Python_app/output/customerCleanedPy.csv')\n",
    "df_book = pd.read_csv('C:/Users/Admin/MVP_Library_Apprenticeship/Python_app/output/bookCleanedPy.csv')\n",
    "\n",
    "# Write to SQL Server\n",
    "df_book.to_sql('Books', con=engine, if_exists='replace', index=False)\n",
    "df_customer.to_sql('Customers', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Data written to SQL Server successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
